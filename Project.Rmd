---
title: "Outliers detection na podstawie zbioru Airbnb New York City 2019"
author: "Jarosław Szewczyk"
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output:
  rmdformats::readthedown:
      highlight: default
---

```{=html}
<style>

/* CHANGE: Default 150% zoom in html file. */

*
{
  font-family: Courier New, monospace;
}

#sidebar
{
  position: fixed;
  top: 0;
  overflow: hidden;
  display: flex;
  flex-direction: column;
  height: 100%;
  background: #14213d; /* navy */
  z-index: 200;
  font-size: 16px;
}

#sidebar a
{
  color: #ffffff; /* Czcionka spisu treści */
  font-weight: normal;
}

#sidebar h2
{
  color: #14213d; /* navy */;
  background: #fca311; /* mango */
}

#sidebar h2 a
{
  color: #14213d; /* navy */;
}

a:hover
{
  color: #ffffff;
  background-color: #bf0063 !important; /* raspberry */
  cursor: pointer;
}

#sidebar a:active
{
  color: #ffffff;
  background-color: #bf0063; /* raspberry */
  cursor: pointer;
}

#postamble
{
  background: #fca311; /* mango */
  border-top: solid 10px #bf0063; /* raspberry */
  font-family: "Lato","proxima-nova","Helvetica Neue",Arial,sans-serif;
  font-size: 90%;
  z-index: 400;
  padding: 12px;
}

#postamble .status
{
  color: #14213d; /* navy */;
  background: red; /* Background of about me section */
  border-top: solid 10px #211103;
  font-size: 90%;
  z-index: 400;
  padding: 12px;
}

#postamble .author
{
  color: #14213d; /* navy */;
  font-weight: bold;
}

#postamble .date
{
  color: #14213d; /* navy */;
}

#content
{
  background: #e5e5e5; /* grey */
}

#content pre
{
  border: 3px solid #bf0063; /* raspberry */
  color: #fca311; /* mango */
}

#content div.sourceCode
{
  background: #e5e5e5; /* grey */
}

#toc ul.nav li.active ul li.active a
{
  background-color: #fca311; /* mango */
  color: #14213d; /* navy */ !important;
  font-weight: normal !important;
}

#toc ul.nav li.active ul li a
{
  background-color: #14213d; /* navy */;
  color: #ffffff;
  font-weight: normal;
  border-right: solid 1px #14213d; /* navy */ !important;
}

#toc ul.nav li.active a
{
  color: #ffffff !important;
  background-color: #fca311
  border-right: solid 0px black !important;
}

#toc ul.nav > li.active > a
{
  color: #14213d; /* navy */;
  background-color: #fca311; /* mango */
}

pre
{
  background-color: #14213d; /* navy */;
  color: #14213d; /* navy */;
}

pre code
{
  color: #fca311; /* mango */
}

td
{
  color: #f7f3eb;
}

p
{
  color: #14213d; /* navy */;
}

h1
{
  color: #14213d; /* navy */;
  text-decoration: none;
  font-family: Courier New, monospace;
}

h2, h3, h4, h5, h6, legend
{
  color: #14213d; /* navy */;
  font-family: Courier New, monospace;
}

code.sourceCode.r
{
  background: #f7f3eb;
  color: #fca311; /* mango */
}

code span.fu, 
code span.at, 
code span.fl,
code span.sc,
code span.dv,
code span.in,
code span.cn,
code span.st,
code span.ot,
code span.cf,
code span.co
{
  color: #fca311; /* mango */
  font-weight: normal;
}

</style>
```

------------------------------------------------------------------------

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Zainstalowanie i załadowanie pakietów

```{r}
#dplyr
if(!require(dplyr)) {
  install.packages("dplyr")
  library(dplyr)
}

#stats
if(!require(stats)) {
  install.packages("stats")
  library(stats)
}

#dbscan
if(!require(dbscan)) {
  install.packages("dbscan")
  library(dbscan)
}

#DepthProc
if(!require(DepthProc)) {
  install.packages("DepthProc")
  library(DepthProc)
}

#rmarkdown
if(!require(rmarkdown)) {
  install.packages("rmarkdown")
  library(rmarkdown)
}

#nortest
if(!require(nortest)) {
  install.packages("nortest")
  library(nortest)
}

#psych
if(!require(psych)) {
  install.packages("psych")
  library(psych)
}

#rmdformats
if(!require(rmdformats)) {
  install.packages("rmdformats")
  library(rmdformats)
}

#robustbase
if(!require(robustbase)) {
  install.packages("robustbase")
  library(robustbase)
}
```

Wczytanie zbioru danych

```{r}
data <- read.csv("https://raw.githubusercontent.com/polishmaverick/WMSO/master/AB_NYC_2019.csv", sep = ",")
```

Wstępna analiza zbioru danych

```{r}
#Wymiary zbioru
dim(data)

#Zmienne i typy danych
str(data)

#Braki danych
colSums(is.na(data))
```

# Wykrywanie elementów odstających - 1 wymiar

## Metoda 1: Reguła 3 sigma

```{r}
#Weryfikacja normalności rozkładu zmiennej

#Test normalności Cramera von Misesa
#cvm.test(data$price, psnorm, mean = mean(data$price), sd = sd(data$price))

threesigma.rule <- function(data, var, t = 3, RemoveNAs = FALSE){
  mu <- mean(data[[var]], na.rm = RemoveNAs)
  sigma <- sd(data[[var]], na.rm = RemoveNAs)
  out <- abs(data[[var]] - mu) > t*sigma
  data.frame(id = data$id[out], var = data[[var]][out])
}

outliers_threesigma <- threesigma.rule(data, "price")
head(outliers_threesigma, 5)
```

## Metoda 2: Metoda Tukeya

```{r}
outliers <- function(data, var, coef = 1.5) {
  bp <- boxplot(data[[var]], plot = FALSE)
  out <- bp$out
  stats <- boxplot.stats(data[[var]], coef = coef, do.conf = FALSE, do.out = TRUE)
  data.frame(id = data$id[data[[var]] %in% stats$out], var = data[[var]][data[[var]] %in% stats$out])
}

outliers_Tukey <- outliers(data, "price")
head(outliers_Tukey, 5)
```

## Metoda 3: Reguła Hampela

```{r}
hampel.rule <- function(data, var_name, t = 3, RemoveNAs = FALSE){
  x <- data[[var_name]]
  mu <- median(x, na.rm = RemoveNAs)
  sig <- mad(x, na.rm = RemoveNAs)
  out <- which(abs(x - mu) > t*sig)
  if (length(out) > 0) {
    data.frame(id = data$id[out], value = x[out])
  } else {
    message("Brak wartości spełniających kryteria.")
    return(NULL)
  }
}

outliers_hampel <- hampel.rule(data, "price")
head(outliers_hampel, 5)
```

## Metoda 4: Z-score

```{r}
data$z_scores <- (abs(data$price - mean(data$price))/sd(data$price))

outliers_zscore_sd <- data[data$z_scores > 3,][,c("id", "price")]
head(outliers_zscore_sd, 5)

###

data$z_scores <- (abs(data$price - median(data$price))/mad(data$price))

outliers_zscore_mad <- data[data$z_scores > 3.5,][,c("id", "price")]
head(outliers_zscore_mad, 5)
```

## Metoda 5: MAD - Median Absolute Deviation

```{r}
MAD <- mad(data$price)
median(data$price) + 3 * MAD

outliers_MAD <- data %>% filter(price > (median(data$price) + 3 * MAD)) 
outliers_MAD <- outliers_MAD[, c("id", "price")]
head(outliers_MAD, 5)
```

## Metoda 6: LOF - Local Outlier Factor
```{r}
#Wybór minPts
lof_scores <- lof(as.matrix(data$price), minPts = 60)
table(lof_scores)
inf_rows <- which(is.infinite(lof_scores))

outliers_LOF <- data[c(inf_rows), c("id", "price")]
head(outliers_LOF, 5)

#Uwaga
max(outliers_LOF$price)
```

## Metoda 7: Depth-based
```{r}
price_depth <- depth(data$price)
cutoffs <- quantile(price_depth, c(0.05))
outlier_ids <- data$id[price_depth < cutoffs]

outliers_depth <- data[data$id %in% outlier_ids, c("id", "price")]
head(outliers_depth, 5)
```

### Do wykrycia wartości odstających można podejść podobnie jak do prognoz, które stawiane są różnymi metodami. Racjonalnym wyborem wydaje się być wyciąganie średniej z prognoz uzyskanych na podstawie różnych metod. W przypadku wartości odstających analogią może być wybór tych obserwacji, które zostały zaklasyfikowane jako outliery przez wszystkie metody lub jak największą liczbę metod.

```{r}
#Ramka danych z podsumowaniem wyników - 1 wymiar
data_one_dim <- data
```

### Zdefiniowanie dla każdej z metod zmiennej om (outliers membership) świadczącej o przynależności do grupy outlierów

```{r}
data_one_dim$om1 <- as.numeric(data$id %in% outliers_threesigma$id)
data_one_dim$om2 <- as.numeric(data$id %in% outliers_Tukey$id)
data_one_dim$om3 <- as.numeric(data$id %in% outliers_hampel$id)
data_one_dim$om4 <- as.numeric(data$id %in% outliers_zscore_sd$id)
data_one_dim$om5 <- as.numeric(data$id %in% outliers_zscore_mad$id)
data_one_dim$om6 <- as.numeric(data$id %in% outliers_MAD$id)
data_one_dim$om7 <- as.numeric(data$id %in% outliers_LOF$id)
data_one_dim$om8 <- as.numeric(data$id %in% outliers_depth$id)
```

### Tabela ze wskazaniami

```{r}
outliers_membership <- grep("om.$", names(data_one_dim), value=TRUE)
data_one_dim$count <- rowSums(data_one_dim[, outliers_membership])
table(data_one_dim$count)
```

### Obserwacje wskazane jako outliery przez wszystkie metody

```{r}
outlier_one_dim <- data_one_dim[data_one_dim$count == max(unique(data_one_dim$count)), c("id", "price")]
outlier_one_dim
```

# Wykrywanie elementów odstających - 2 wymiary lub więcej

### Wybór zmiennych do wykrywania outlierów - 2 wymiary lub więcej
```{r}
vars <- c("price",
          "minimum_nights",
          "calculated_host_listings_count",
          "availability_365",
          "number_of_reviews")

data_subset <- data[, vars]
```


## Metoda 1: PCA (Analiza czynnikowa)
```{r}
### Test Kaisera-Meyera-Olkina
KMO(data_subset)

### Analiza czynnikowa
pca <- prcomp(data_subset, scale. = TRUE)

### Obliczenie odległości od punktu środkowego PCA
data_subset_pca <- predict(pca, data_subset)
distances <- apply(data_subset_pca, 1, function(x) sqrt(sum(x^2)))

### Wybór obserwacji z odległością większą niż 3 razy odchylenie standardowe
threshold <- mean(distances) + 3*sd(distances)
outliers <- which(distances > threshold)

### wyświetlenie ramki danych z wartościami odstającymi
outliers_PCA <- data[c(outliers), c("id", "price")]
head(outliers_PCA, 5)
```

## Metoda 2: Odległość Mahalanobisa
```{r}
m_dist <- mahalanobis(data_subset, colMeans(data_subset), cov(data_subset))
threshold <- sqrt(qchisq(p = 0.975, df = ncol(data_subset)))

data_subset[m_dist > threshold,]

### Obliczenie odległości
distances <- mahalanobis(data_subset, colMeans(data_subset), cov(data_subset))

###
cutoff <- qchisq(p = 0.95 , df = ncol(data_subset))

### Display observation whose distance greater than cutoff value
outliers_Mahalanobis <- data[distances > cutoff ,]
head(outliers_Mahalanobis, 5)
```

## Metoda 3: Metoda DBSCAN (Density-based Spatial Clustering of Applications with Noise)
```{r}
### Podział zbioru na 10 części ze względów wydajnościowych
split_data_subset <- split(data_subset, rep(1:10, length.out = nrow(data_subset)))

### Funkcja do analizy każdej części danych przy użyciu dbscan
analyze_subset <- function(data_subset_subset, eps, MinPts)
{
  dbscan(data_subset_subset, eps = eps, MinPts = MinPts)
}

### Analiza każdej części danych przy użyciu funkcji lapply
results <- lapply(split_data_subset, analyze_subset, eps = 100, MinPts = 60)

outliers <- c()
for (i in seq_along(results)) {
  subset_outliers <- which(results[[i]]$cluster == 0)
  outliers <- c(outliers, subset_outliers)
}

outliers_DBSCAN <- as.data.frame(outliers)
head(outliers_DBSCAN, 50)
```